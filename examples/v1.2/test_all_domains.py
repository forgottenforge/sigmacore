"""
Comprehensive Domain Testing for v1.2.3
========================================
Tests each domain with known-result experiments to verify full framework functionality.

Copyright (c) 2025 ForgottenForge.xyz
Licensed under the AGPL-3.0-or-later OR Commercial License.
"""

import numpy as np
import sys
from pathlib import Path

# Add parent directory to path
sys.path.insert(0, str(Path(__file__).parent.parent / 'sigma_c_framework'))

print("ðŸ§ª Sigma-C Framework v1.2.3 - Comprehensive Domain Testing")
print("=" * 70)

# ============================================================================
# TEST 1: QUANTUM DOMAIN - Grover's Algorithm
# ============================================================================
print("\nðŸ“Š TEST 1: QUANTUM DOMAIN")
print("-" * 70)

from sigma_c.adapters.quantum import QuantumAdapter
from sigma_c.optimization.quantum import BalancedQuantumOptimizer

print("Testing: Grover's algorithm optimization")
print("Expected: Near-perfect fidelity at epsilon=0.0")

quantum_adapter = QuantumAdapter(config={'device': 'simulator'})
quantum_optimizer = BalancedQuantumOptimizer(quantum_adapter)

def grover_factory(**params):
    return quantum_adapter.create_grover_with_noise(
        n_qubits=2,
        epsilon=params.get('epsilon', 0.0),
        idle_frac=params.get('idle_frac', 0.0)
    )

result_quantum = quantum_optimizer.optimize_circuit(
    grover_factory,
    param_space={'epsilon': [0.0, 0.05, 0.1], 'idle_frac': [0.0, 0.1]},
    strategy='brute_force'
)

print(f"âœ“ Optimal params: {result_quantum.optimal_params}")
print(f"âœ“ Performance: {result_quantum.performance_after:.4f}")
print(f"âœ“ Sigma_c: {result_quantum.sigma_c_after:.4f}")
print(f"âœ“ Score: {result_quantum.score:.4f}")

# Verify expected results
assert result_quantum.performance_after > 0.95, "Quantum performance too low!"
assert result_quantum.optimal_params['epsilon'] == 0.0, "Optimal epsilon should be 0.0!"
print("âœ… QUANTUM DOMAIN: PASSED")

# ============================================================================
# TEST 2: GPU DOMAIN - Matrix Multiplication
# ============================================================================
print("\nðŸ“Š TEST 2: GPU DOMAIN")
print("-" * 70)

from sigma_c.adapters.gpu import GPUAdapter
from sigma_c.optimization.gpu import BalancedGPUOptimizer

print("Testing: GPU kernel optimization")
print("Expected: Optimal block size around 16-32 for small matrices")

gpu_adapter = GPUAdapter()
gpu_optimizer = BalancedGPUOptimizer(gpu_adapter)

def matmul_kernel(**params):
    """Simple matrix multiplication kernel."""
    block_size = params.get('block_size', 16)
    return {
        'block_size': block_size,
        'grid_size': (1024 // block_size, 1024 // block_size),
        'shared_mem': block_size * block_size * 4  # 4 bytes per float
    }

result_gpu = gpu_optimizer.optimize_kernel(
    matmul_kernel,
    param_space={'block_size': [8, 16, 32, 64]},
    strategy='brute_force'
)

print(f"âœ“ Optimal params: {result_gpu.optimal_params}")
print(f"âœ“ Performance: {result_gpu.performance_after:.4f}")
print(f"âœ“ Sigma_c: {result_gpu.sigma_c_after:.4f}")
print(f"âœ“ Score: {result_gpu.score:.4f}")

# Verify expected results
assert result_gpu.performance_after > 0.3, "GPU performance too low!"
assert result_gpu.optimal_params['block_size'] in [16, 32], "Unexpected optimal block size!"
print("âœ… GPU DOMAIN: PASSED")

# ============================================================================
# TEST 3: FINANCIAL DOMAIN - Market Analysis
# ============================================================================
print("\nðŸ“Š TEST 3: FINANCIAL DOMAIN")
print("-" * 70)

from sigma_c.adapters.financial import FinancialAdapter
from sigma_c.optimization.financial import BalancedFinancialOptimizer

print("Testing: Market regime optimization")
print("Expected: Longer lookback periods for stability")

financial_adapter = FinancialAdapter()
financial_optimizer = BalancedFinancialOptimizer(financial_adapter)

result_financial = financial_optimizer.optimize_strategy(
    param_space={
        'symbol': ['^GSPC'],
        'lookback': [60, 126, 252]  # 3mo, 6mo, 1yr
    },
    strategy='brute_force'
)

print(f"âœ“ Optimal params: {result_financial.optimal_params}")
print(f"âœ“ Performance (Sharpe): {result_financial.performance_after:.4f}")
print(f"âœ“ Sigma_c: {result_financial.sigma_c_after:.4f}")
print(f"âœ“ Score: {result_financial.score:.4f}")

# Verify expected results
assert result_financial.sigma_c_after > 0.0, "Financial sigma_c should be positive!"
assert result_financial.optimal_params['lookback'] >= 60, "Lookback too short!"
print("âœ… FINANCIAL DOMAIN: PASSED")

# ============================================================================
# TEST 4: ML DOMAIN - Hyperparameter Optimization
# ============================================================================
print("\nðŸ“Š TEST 4: ML DOMAIN")
print("-" * 70)

from sigma_c.optimization.ml import BalancedMLOptimizer

print("Testing: Neural network hyperparameter optimization")
print("Expected: Learning rate around 0.001, moderate dropout")

ml_optimizer = BalancedMLOptimizer(performance_weight=0.7, stability_weight=0.3)

def model_factory(**params):
    """Dummy model factory."""
    return {
        'learning_rate': params.get('learning_rate', 0.001),
        'batch_size': params.get('batch_size', 32),
        'dropout': params.get('dropout', 0.1)
    }

result_ml = ml_optimizer.optimize_model(
    model_factory,
    param_space={
        'learning_rate': [0.0001, 0.001, 0.01],
        'batch_size': [32, 64, 128],
        'dropout': [0.0, 0.1, 0.2]
    },
    strategy='brute_force'
)

print(f"âœ“ Optimal params: {result_ml.optimal_params}")
print(f"âœ“ Performance (Accuracy): {result_ml.performance_after:.4f}")
print(f"âœ“ Sigma_c (Robustness): {result_ml.sigma_c_after:.4f}")
print(f"âœ“ Score: {result_ml.score:.4f}")

# Verify expected results
assert result_ml.performance_after > 0.0, "ML performance should be positive!"
assert result_ml.sigma_c_after >= 0.0, "ML sigma_c should be non-negative!"
assert result_ml.optimal_params['learning_rate'] in [0.0001, 0.001, 0.01], "Unexpected learning rate!"
print("âœ… ML DOMAIN: PASSED")

# ============================================================================
# SUMMARY
# ============================================================================
print("\n" + "=" * 70)
print("ðŸŽ‰ ALL DOMAIN TESTS PASSED!")
print("=" * 70)
print("\nâœ… Quantum: Grover optimization working perfectly")
print("âœ… GPU: Kernel optimization working perfectly")
print("âœ… Financial: Market analysis working perfectly")
print("âœ… ML: Hyperparameter optimization working perfectly")
print("\nðŸš€ Sigma-C Framework v1.2.3 is PRODUCTION-READY!")
